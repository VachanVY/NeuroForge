{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e03bb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import typing as tp\n",
    "from torch.nn import functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Content from functional.py\n",
    "FAN_IN:tp.TypeAlias = int\n",
    "FAN_OUT:tp.TypeAlias = int\n",
    "KERNEL_SIZE:tp.TypeAlias = tuple[int, int]\n",
    "STRIDES:tp.TypeAlias = tuple[int, int]\n",
    "\n",
    "\n",
    "def linear_forward(\n",
    "    x:Tensor,      # (B, fi)\n",
    "    wie:Tensor,    # (fo, fi)\n",
    "    bias:Tensor,   # (fo,)\n",
    "):\n",
    "    return x @ wie.transpose(-1, -2) + bias.unsqueeze(0) \n",
    "\n",
    "def linear_backward(\n",
    "    x:Tensor,       # (B, fi)\n",
    "    wie:Tensor,     # (fo, fi)\n",
    "    bias:Tensor,    # (fo,) # we dont need this anyway\n",
    "    dL_dO:Tensor,   # (B, fo)\n",
    "):\n",
    "    dL_dx = dL_dO @ wie      # (B, fi) <= (B, fo) @ (fo, fi)\n",
    "    dL_dwie = dL_dO.transpose(-1, -2) @ x    # (fo, fi) <= (B, fo).T @ (B, fi)\n",
    "    dL_db = dL_dO.sum(dim=0) # (fo,) <= (B, fo)\n",
    "    return dL_dx, dL_dwie, dL_db\n",
    "\n",
    "\n",
    "def reshape_forward(x:Tensor, shape:tuple): # (B, C, H, W)\n",
    "    return x.reshape(shape), x.shape        # (B, C*H*W), (B, C, H, W)\n",
    "\n",
    "\n",
    "def reshape_backward(dL_dO:Tensor, x_shape:torch.Size): # (B, C*H*W)\n",
    "    return dL_dO.reshape(x_shape)                       # (B, C, H, W)\n",
    "\n",
    "def _conv2d(\n",
    "    x:Tensor, # (H, W)\n",
    "    w:Tensor, # (h, w)\n",
    "    full:bool=False,\n",
    "    convolve:bool=False\n",
    "):\n",
    "    x = x[None, None, ...] # (1, 1, H, W)\n",
    "    w = w[None, None, ...] # (1, 1, h, w)\n",
    "    if full:\n",
    "        pad_h = w.size(-2) - 1\n",
    "        pad_w = w.size(-1) - 1\n",
    "        x = F.pad(x, (pad_w, pad_w, pad_h, pad_h), mode='constant')\n",
    "    if convolve:\n",
    "        w = w.flip((2, 3))\n",
    "    return F.conv2d(\n",
    "        input=x, # (1, 1, H, W)\n",
    "        weight=w, # (1, 1, h, w)\n",
    "        stride=1\n",
    "    )[0, 0, :, :]\n",
    "\n",
    "\n",
    "def _dilate_matrix(x:Tensor, dilation:tuple[int, int]):\n",
    "    \"\"\"`x: shape(B, C, H, W)`\\n `dilation:tuple`\"\"\"\n",
    "    (B, C, H, W), (Hd, Wd)  = x.shape, dilation\n",
    "    dilated = torch.zeros((B, C, Hd*(H-1)+1, Wd*(W-1)+1 ), device=x.device, dtype=x.dtype)\n",
    "    dilated[:, :, ::Hd, ::Wd] = x\n",
    "    return dilated\n",
    "\n",
    "\n",
    "def conv2d_forward(\n",
    "    x:Tensor,               # (B, fi, H, W) \n",
    "    wie:Tensor,               # (fo, fi, h, w)\n",
    "    bias:tp.Optional[Tensor],  # (fo,)\n",
    "    stride:STRIDES = (1, 1)\n",
    "):\n",
    "    B, C, H, W = x.shape\n",
    "    fo, fi, h, w = wie.shape\n",
    "    sh, sw = stride\n",
    "    assert C == fi, f\"Expected {C} == {fi}\"\n",
    "    assert H >= h, f\"Expected {H} >= {h}\"\n",
    "    assert W >= w, f\"Expected {W} >= {w}\"\n",
    "    if bias is not None:\n",
    "        assert bias.shape[0] == fo, f\"Expected {bias.shape[0]} == {fo}\"\n",
    "\n",
    "    output_shape = (B, fo, int((H-h)//sh + 1), int((W-w)//sw + 1))\n",
    "    out = torch.zeros(output_shape, device=x.device, dtype=x.dtype) # (B, C_out, H1, W1)\n",
    "    for fan_out in range(fo):\n",
    "        for fan_in in range(fi):\n",
    "            for bdim in range(B):\n",
    "                out[bdim, fan_out] += _conv2d(x[bdim, fan_in], wie[fan_out, fan_in])[::sh, ::sw]\n",
    "\n",
    "    if bias is not None:\n",
    "        out += bias.view(1, -1, 1, 1)\n",
    "    return out\n",
    "\n",
    "\n",
    "def conv2d_backward(\n",
    "    x:Tensor,                   # (B, fi, H, W)\n",
    "    wei:Tensor,                 # (fo, fi, h, w)\n",
    "    bias:tp.Optional[Tensor],   # (fo,)\n",
    "    dL_dO:Tensor,               # (B, fo, H1, W1)\n",
    "    stride:STRIDES = (1, 1)\n",
    "):  \n",
    "    fo, fi, h, w = wei.shape\n",
    "    B, C, H, W = x.shape\n",
    "\n",
    "    dL_dx, dL_dwei = torch.zeros_like(x), torch.zeros_like(wei)\n",
    "    dL_dO = _dilate_matrix(dL_dO, dilation=stride)\n",
    "    for fan_out in range(fo): # C_out\n",
    "        for bdim in range(B): # B\n",
    "            for fan_in in range(fi): # C_in\n",
    "                dL_dwei[fan_out, fan_in] += _conv2d(x[bdim, fan_in], dL_dO[bdim, fan_out]) # (H, W)*(H1, W1) => (Hk, Wk)\n",
    "                dL_dx[bdim, fan_in] += _conv2d(dL_dO[bdim, fan_out], wei[fan_out, fan_in], full=True, convolve=True) # (H1, W1)*(Hk, Wk) => (H, W)\n",
    "    \n",
    "    dL_db = dL_dO.sum(dim=(0, 2, 3)) if bias is not None else None\n",
    "    return dL_dx, dL_dwei, dL_db\n",
    "\n",
    "\n",
    "def _maxpool(matrix:Tensor, kernel_size:KERNEL_SIZE, strides:STRIDES): # (H, W)\n",
    "        (H, W), (Hk, Wk), (Hs, Ws) = matrix.shape, kernel_size, strides\n",
    "        output_shape = ((H-Hk+1)//Hs + 1, (W-Wk+1)//Ws + 1)\n",
    "        indices, maxpooled = [], []\n",
    "        for i in range(0, H - Hk + 1, Hs):\n",
    "            for j in range(0, W - Wk + 1, Ws):\n",
    "                window = matrix[i:i+Hk, j:j+Wk]\n",
    "                max_index = torch.unravel_index(torch.argmax(window), window.shape)\n",
    "                max_index_global = (max_index[0] + i, max_index[1] + j)\n",
    "                indices.append(max_index_global)\n",
    "                maxpooled.append(window[max_index])\n",
    "        maxpooled = torch.stack(maxpooled).reshape(output_shape)\n",
    "        indices = torch.tensor(indices) # (H1*W1, 2)\n",
    "        return maxpooled, (indices[:, 0].reshape(output_shape), indices[:, 1].reshape(output_shape))\n",
    "\n",
    "def channeled_maxpool(matrix:Tensor, kernel_size:KERNEL_SIZE, strides:STRIDES): # (C, H, W)\n",
    "    (C, H, W) = matrix.shape\n",
    "    maxpooled, Rindices, Cindices = [], [], []\n",
    "    for c in range(C):\n",
    "        maxpooled_, (indices_r, indices_c) = _maxpool(matrix[c], kernel_size, strides)\n",
    "        maxpooled.append(maxpooled_)\n",
    "        Rindices.append(indices_r)\n",
    "        Cindices.append(indices_c)\n",
    "    return torch.stack(maxpooled), (torch.stack(Rindices), torch.stack(Cindices))\n",
    "\n",
    "\n",
    "def vmaxpool(matrix:Tensor, kernel_size:KERNEL_SIZE, strides:STRIDES): # (B, C, H, W)\n",
    "    (B, C, H, W) = matrix.shape\n",
    "    maxpooled, Rindices, Cindices = [], [], []\n",
    "    for b in range(B):\n",
    "        maxpooled_b, (indices_r, indices_c) = channeled_maxpool(matrix[b], kernel_size, strides)\n",
    "        maxpooled.append(maxpooled_b)\n",
    "        Rindices.append(indices_r)\n",
    "        Cindices.append(indices_c)\n",
    "    return torch.stack(maxpooled), (torch.stack(Rindices), torch.stack(Cindices))\n",
    "\n",
    "\n",
    "def maxpool2d_forward(\n",
    "    x:Tensor,\n",
    "    kernel_size:KERNEL_SIZE,\n",
    "    strides:STRIDES,\n",
    ") -> tuple[Tensor, tuple[Tensor, Tensor], torch.Size]:\n",
    "    O, (ridx, cidx) = vmaxpool(x, kernel_size, strides)\n",
    "    return O, (ridx, cidx), x.shape\n",
    "\n",
    "\n",
    "def maxpool2d_backward(\n",
    "    dL_dO: Tensor,\n",
    "    x_shape: torch.Size,\n",
    "    indices: tuple[Tensor, Tensor],\n",
    "):\n",
    "    (ridx, cidx) = indices\n",
    "    dL_dX = torch.zeros(x_shape, device=dL_dO.device)\n",
    "    B, C, H, W = dL_dO.shape\n",
    "    for b in range(B):\n",
    "        for c in range(C):\n",
    "            dL_dO_bc = dL_dO[b, c]\n",
    "            ridx_bc = ridx[b, c]\n",
    "            cidx_bc = cidx[b, c]\n",
    "            dL_dX[b, c, ridx_bc, cidx_bc] += dL_dO_bc\n",
    "    return dL_dX\n",
    "\n",
    "\n",
    "def relu_forward(x:Tensor):\n",
    "    return torch.maximum(x, torch.zeros((), dtype=x.dtype, device=x.device))\n",
    "\n",
    "\n",
    "def relu_backward(relu:Tensor, dL_dO:Tensor):\n",
    "    return dL_dO * (relu > 0).to(relu.dtype)\n",
    "\n",
    "\n",
    "def softmax_forward(logits:Tensor):\n",
    "    max_val, idx = logits.max(-1, keepdim=True) \n",
    "    logits -= max_val\n",
    "    exp = torch.exp(logits)\n",
    "    proba = exp / exp.sum(-1, keepdim=True)\n",
    "    return proba\n",
    "\n",
    "\n",
    "def softmax_backward(probs:Tensor, dL_dprobs:Tensor):\n",
    "    nc = probs.shape[-1]\n",
    "    t1 = torch.einsum(\"ij,ik->ijk\", probs, probs)\n",
    "    t2 = torch.einsum(\"ij,jk->ijk\", probs, torch.eye(nc, nc, device=probs.device, dtype=probs.dtype))\n",
    "    dprobs_dlogits = t2 - t1\n",
    "    dL_dlogits = (dL_dprobs[:, None, :] @ dprobs_dlogits)[:, 0, :]\n",
    "    return dL_dlogits\n",
    "\n",
    "\n",
    "def cross_entropy_forward(y_true:Tensor, y_proba:Tensor):\n",
    "    log_probs = torch.log(y_proba)\n",
    "    loss = -log_probs[torch.arange(len(y_true)), y_true].mean()\n",
    "    return loss\n",
    "\n",
    "\n",
    "def cross_entropy_backward(y_true:Tensor, y_proba:Tensor):\n",
    "    B = len(y_true)\n",
    "    dL_dlogprobas = torch.zeros_like(y_proba)\n",
    "    dL_dlogprobas[torch.arange(B), y_true] = -1/B\n",
    "    dlogprobas_dprobas = 1/y_proba\n",
    "    dL_dprobas = dL_dlogprobas * dlogprobas_dprobas\n",
    "    return dL_dprobas\n",
    "\n",
    "\n",
    "# Content from nn.py\n",
    "_sqrt = lambda x: x**0.5\n",
    "_prod = lambda x: x[0]*x[1]\n",
    "\n",
    "class Module:\n",
    "    def forward(self, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "    def backward(self, *args, **kwargs):\n",
    "        raise NotImplementedError\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.forward(*args, **kwargs)\n",
    "\n",
    "    def to(self, device):\n",
    "        for attr_name in dir(self):\n",
    "            attr = getattr(self, attr_name)\n",
    "            if isinstance(attr, Tensor):\n",
    "                setattr(self, attr_name, attr.to(device))\n",
    "            elif isinstance(attr, Module):\n",
    "                attr.to(device)\n",
    "        return self\n",
    "\n",
    "\n",
    "class Linear(Module):\n",
    "    def __init__(self, fan_in:int, fan_out:int):\n",
    "        super().__init__()\n",
    "        bound = _sqrt(2/fan_in)\n",
    "        self.wie = torch.randn(fan_out, fan_in).uniform_(-bound, bound)\n",
    "        self.bias = torch.randn(fan_out)\n",
    "\n",
    "    def forward(self, x:Tensor):\n",
    "        return linear_forward(x, self.wie, self.bias)\n",
    "    def backward(self, x:Tensor, dL_dO:Tensor):\n",
    "        return linear_backward(x, self.wie, self.bias, dL_dO)\n",
    "\n",
    "\n",
    "class Reshape(Module):\n",
    "    def __init__(self, shape:tuple):\n",
    "        super().__init__()\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, x:Tensor):\n",
    "        self.x_shape = x.shape\n",
    "        reshaped, _ = reshape_forward(x, self.shape)\n",
    "        return reshaped\n",
    "    def backward(self, dL_dO:Tensor):\n",
    "        return reshape_backward(dL_dO, self.x_shape)\n",
    "\n",
    "\n",
    "class Conv2d(Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels:FAN_IN,\n",
    "        out_channels:FAN_OUT,\n",
    "        kernel_size:KERNEL_SIZE,\n",
    "        strides:STRIDES,\n",
    "        bias:bool=True\n",
    "    ):\n",
    "        bound = _sqrt(2/_prod(kernel_size))\n",
    "        self.wei = torch.empty(size=(out_channels, in_channels, *kernel_size)).uniform_(-bound, bound)\n",
    "        self.bias = torch.zeros(size=(out_channels,)) if bias else None\n",
    "        self.strides = strides\n",
    "\n",
    "    def forward(self, x:Tensor):\n",
    "        self.x = x; return conv2d_forward(x, self.wei, self.bias, self.strides)\n",
    "    def backward(self, dL_dO:Tensor):\n",
    "        return conv2d_backward(self.x, self.wei, self.bias, dL_dO, self.strides)\n",
    "\n",
    "\n",
    "class Maxpool2d(Module):\n",
    "    def __init__(self, kernel_size:KERNEL_SIZE, strides:STRIDES):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.strides = strides\n",
    "\n",
    "    def forward(self, x:Tensor):\n",
    "        out, self.idx, self.x_shape = maxpool2d_forward(x, self.kernel_size, self.strides)\n",
    "        return out\n",
    "    def backward(self, dL_dO:Tensor):\n",
    "        return maxpool2d_backward(dL_dO, self.x_shape, self.idx)\n",
    "\n",
    "\n",
    "class ReLU(Module):\n",
    "    def forward(self, x:Tensor):\n",
    "        self.relu = relu_forward(x)\n",
    "        return self.relu\n",
    "    def backward(self, dL_dO:Tensor):\n",
    "        return relu_backward(self.relu, dL_dO)\n",
    "\n",
    "\n",
    "class Softmax(Module):\n",
    "    def forward(self, x:Tensor, axis:int=-1):\n",
    "        assert axis == -1, \"Softmax only supports the last axis... for now :/\"\n",
    "        self.probs = softmax_forward(x)\n",
    "        return self.probs\n",
    "    def backward(self, dL_dO:Tensor):\n",
    "        return softmax_backward(self.probs, dL_dO)\n",
    "\n",
    "\n",
    "class CrossEntropy:\n",
    "    def forward(self, y_true:Tensor, y_proba:Tensor):\n",
    "        self.y_true = y_true\n",
    "        self.y_proba = y_proba\n",
    "        return cross_entropy_forward(y_true, y_proba)\n",
    "    def backward(self):\n",
    "        return cross_entropy_backward(self.y_true, self.y_proba)\n",
    "\n",
    "\n",
    "# Content from lenet.py\n",
    "class LeNet(Module):\n",
    "    def __init__(self, num_classes:int = 10):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2d(in_channels=1, out_channels=6, kernel_size=(5, 5), strides=(1, 1), bias=True)\n",
    "        self.pool1 = Maxpool2d(kernel_size=(2, 2), strides=(2, 2))\n",
    "        self.conv2 = Conv2d(in_channels=6, out_channels=16, kernel_size=(5, 5), strides=(1, 1), bias=True)\n",
    "        self.pool2 = Maxpool2d(kernel_size=(2, 2), strides=(2, 2))\n",
    "        self.flatten = Reshape(shape=(-1, 400))\n",
    "        self.fc1 = Linear(fan_in=400, fan_out=120)\n",
    "        self.relu1 = ReLU()\n",
    "        self.fc2 = Linear(fan_in=120, fan_out=84)\n",
    "        self.relu2 = ReLU()\n",
    "        self.fc3 = Linear(fan_in=84, fan_out=num_classes)\n",
    "        self.softmax = Softmax()\n",
    "        self.criterion = CrossEntropy()\n",
    "        self.activations = {}\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.conv1(x)\n",
    "        self.activations['conv1'] = x\n",
    "        x = self.pool1(x)\n",
    "        self.activations['pool1'] = x\n",
    "        x = self.conv2(x)\n",
    "        self.activations['conv2'] = x\n",
    "        x = self.pool2(x)\n",
    "        self.activations['pool2'] = x\n",
    "        x = self.flatten(x)\n",
    "        self.activations['flatten'] = x\n",
    "        x = self.fc1(x)\n",
    "        self.activations['fc1'] = x\n",
    "        x = self.relu1(x)\n",
    "        self.activations['relu1'] = x\n",
    "        x = self.fc2(x)\n",
    "        self.activations['fc2'] = x\n",
    "        x = self.relu2(x)\n",
    "        self.activations['relu2'] = x\n",
    "        x = self.fc3(x)\n",
    "        self.activations['fc3'] = x\n",
    "        x = self.softmax(x)\n",
    "        self.activations['softmax'] = x\n",
    "        return x\n",
    "    \n",
    "    def backward(self) -> dict:\n",
    "        dL_dO = self.criterion.backward()\n",
    "        dL_dO = self.softmax.backward(dL_dO)\n",
    "        dL_dO, dL_dw3, dL_db3 = self.fc3.backward(self.activations['relu2'], dL_dO)\n",
    "        dL_dO = self.relu2.backward(dL_dO)\n",
    "        dL_dO, dL_dw2, dL_db2 = self.fc2.backward(self.activations['relu1'], dL_dO)\n",
    "        dL_dO = self.relu1.backward(dL_dO)\n",
    "        dL_dO, dL_dw1, dL_db1 = self.fc1.backward(self.activations['flatten'], dL_dO)\n",
    "        dL_dO = self.flatten.backward(dL_dO)\n",
    "        dL_dO = self.pool2.backward(dL_dO)\n",
    "        dL_dO, dL_dw_conv2, dL_db_conv2 = self.conv2.backward(dL_dO)\n",
    "        dL_dO = self.pool1.backward(dL_dO)\n",
    "        dL_dinput, dL_dw_conv1, dL_db_conv1 = self.conv1.backward(dL_dO)\n",
    "        \n",
    "        return {\n",
    "            'input_grad': dL_dinput,\n",
    "            'conv1_weight_grad': dL_dw_conv1,\n",
    "            'conv1_bias_grad': dL_db_conv1,\n",
    "            'conv2_weight_grad': dL_dw_conv2,\n",
    "            'conv2_bias_grad': dL_db_conv2,\n",
    "            'fc1_weight_grad': dL_dw1,\n",
    "            'fc1_bias_grad': dL_db1,\n",
    "            'fc2_weight_grad': dL_dw2,\n",
    "            'fc2_bias_grad': dL_db2,\n",
    "            'fc3_weight_grad': dL_dw3,\n",
    "            'fc3_bias_grad': dL_db3,\n",
    "        }\n",
    "    \n",
    "    def compute_loss(self, x: Tensor, y_true: Tensor) -> Tensor:\n",
    "        y_pred = self.forward(x)\n",
    "        loss = self.criterion.forward(y_true, y_pred)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada57bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Content from train_lenet.py\n",
    "device = \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,)) # Normalize to [-1, 1] range\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root='./data', train=True, download=True, transform=transform\n",
    ")\n",
    "test_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root='./data', train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)\n",
    "\n",
    "model = LeNet(num_classes=10).to(device)\n",
    "\n",
    "num_epochs = 10\n",
    "print(\"Starting training on Fashion MNIST...\")\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    for i, (images, labels) in enumerate(pbar):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        loss = model.compute_loss(images, labels)\n",
    "        gradients = model.backward()\n",
    "        \n",
    "        lr = 0.01\n",
    "        with torch.no_grad():\n",
    "            model.conv1.wei -= lr * gradients['conv1_weight_grad']\n",
    "            model.conv1.bias -= lr * gradients['conv1_bias_grad']\n",
    "            model.conv2.wei -= lr * gradients['conv2_weight_grad']\n",
    "            model.conv2.bias -= lr * gradients['conv2_bias_grad']\n",
    "            model.fc1.wie -= lr * gradients['fc1_weight_grad']\n",
    "            model.fc1.bias -= lr * gradients['fc1_bias_grad']\n",
    "            model.fc2.wie -= lr * gradients['fc2_weight_grad']\n",
    "            model.fc2.bias -= lr * gradients['fc2_bias_grad']\n",
    "            model.fc3.wie -= lr * gradients['fc3_weight_grad']\n",
    "            model.fc3.bias -= lr * gradients['fc3_bias_grad']\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "\n",
    "    print(f\"Epoch {epoch+1} average loss: {running_loss / len(train_loader):.4f}\")\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model.forward(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Accuracy on the test set after epoch {epoch+1}: {accuracy:.2f}%\")\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9398ecad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6114a4d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfb0d50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b564c39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea730645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de68342d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01af467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f495fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fb16b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NeuroForge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
