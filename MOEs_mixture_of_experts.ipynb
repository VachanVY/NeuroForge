{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import typing as tp\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import (\n",
    "    nn, Tensor\n",
    ")\n",
    "import torch.utils.data\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(), # [0, 255] -> [0.0, 1.0]\n",
    "        torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # [0.0, 1.0] -> [-1.0, 1.0]\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True,\n",
    "    transform=transforms\n",
    ")\n",
    "train_data = trainset.data\n",
    "y_train = trainset.targets\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True,\n",
    "    # transform=transforms\n",
    ")\n",
    "X_VAL = torch.stack([transforms(x) for x in testset.data])\n",
    "y_val = torch.tensor(testset.targets)\n",
    "NUM_CLASSES:int = len(np.unique(y_train)) # 10\n",
    "\n",
    "FAN_IN:int = train_data.shape[1] * train_data.shape[2] * train_data.shape[3] # (3*32*32) = 3072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset.data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(X:np.ndarray, y:np.ndarray, labels=trainset.classes):\n",
    "    plt.figure(figsize=(1, 1))\n",
    "    plt.imshow(X)\n",
    "    plt.title(labels[y])\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image(train_data[0], y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        fan_in:int,\n",
    "        hidden_units:int,\n",
    "        fan_out:int\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dense1 = nn.Linear(fan_in, hidden_units); self.relu1 = nn.ReLU()\n",
    "        self.dense2 = nn.Linear(hidden_units, hidden_units); self.relu2 = nn.ReLU()\n",
    "        self.dense3 = nn.Linear(hidden_units, fan_out); self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x:Tensor) -> Tensor: # (B, C=3, H=32, W=32)\n",
    "        x = x.flatten(1)                # (B, C*H*W)\n",
    "        x = self.relu1(self.dense1(x))  # (B, hidden_units)\n",
    "        x = self.relu2(self.dense2(x))  # (B, hidden_units)\n",
    "        return self.dense3(x)           # (B, fan_out)\n",
    "    \n",
    "print(\"DenseModel:\", DenseModel(3*32*32, 100, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixtureOfExperts(nn.Module):\n",
    "    def __init__(self, num_experts:int, fan_in:int, fan_out:int, topk:int):\n",
    "        super().__init__()\n",
    "        self.num_experts = num_experts\n",
    "        self.topk = topk\n",
    "\n",
    "        self.gate_values_func = nn.Linear(fan_in, num_experts, bias=False)\n",
    "        self.load_balancing_noise = nn.Linear(fan_in, num_experts, bias=False)\n",
    "\n",
    "        self.expert_modules = nn.ModuleList([\n",
    "            nn.Linear(fan_in, fan_out) for _ in range(num_experts)\n",
    "        ])\n",
    "\n",
    "    def gate_network(self, x:Tensor, topk:int):\n",
    "        \"\"\"takes input x and returns the gate values for each expert\"\"\"\n",
    "        hx = (\n",
    "            self.gate_values_func(x) +\n",
    "            torch.normal(mean=0, std=1, size=(x.size(0), self.num_experts), device=x.device) * self.load_balancing_noise(x)\n",
    "        ) # (B, num_experts)\n",
    "\n",
    "        topk_values, topk_indices = torch.topk(hx, topk, dim=1)\n",
    "\n",
    "        hx = torch.full_like(hx, -torch.inf)\n",
    "        hx.scatter_(dim=1, index=topk_indices, src=topk_values)\n",
    "        return torch.softmax(hx, dim=1)\n",
    "        \n",
    "    def expert_gate_dot_product(\n",
    "        self,\n",
    "        x:Tensor,           # (B, fan_in)\n",
    "        gate_values:Tensor  # (B, num_experts)\n",
    "    ):\n",
    "        \"\"\"when the gated value function returns 0, we need not compute that expert function\"\"\"\n",
    "        expert_outputs:list[Tensor] = [] # (B, 1, fan_out)\n",
    "        # (1, fan_in) # (num_experts,)\n",
    "        for xi,       expert_gate_vals in zip(x.unsqueeze(1), gate_values):\n",
    "            per_batch_expert_outputs = [] # (num_sel_experts, 1, fan_out)\n",
    "            #   (,)\n",
    "            for gate_val, expert_module in zip(expert_gate_vals, self.expert_modules):\n",
    "                if gate_val == 0:\n",
    "                    continue\n",
    "                per_batch_expert_outputs.append(expert_module(xi)*gate_val) # (1, fan_out)\n",
    "            out:Tensor = torch.stack(per_batch_expert_outputs).sum(dim=0)\n",
    "            expert_outputs.append(out) # (1, fan_out)\n",
    "        return torch.cat(expert_outputs, dim=0).squeeze(1) # (B, 1, fan_out) => (B, fan_out)\n",
    "\n",
    "    def forward(self, x:Tensor): # (B, fan_in)\n",
    "        gate_values = self.gate_network(x, self.topk) # (B, num_experts)\n",
    "        x = self.expert_gate_dot_product(x, gate_values)\n",
    "        return x, gate_values\n",
    "\n",
    "\n",
    "class MoEDenseModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        fan_in:int,\n",
    "        hidden_units:int,\n",
    "        fan_out:int,\n",
    "        num_experts:int,\n",
    "        topk:int\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_experts = num_experts\n",
    "\n",
    "        self.dense1 = nn.Linear(fan_in, hidden_units); self.relu1 = nn.ReLU()\n",
    "        self.moe_dense2 = MixtureOfExperts(num_experts, hidden_units, hidden_units, topk); self.relu2 = nn.ReLU()\n",
    "        self.dense3 = nn.Linear(hidden_units, fan_out); self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x:Tensor):\n",
    "        x = x.flatten(1)                    # (B, fan_in=C*H*W)\n",
    "        x = self.relu1(self.dense1(x))      # (B, hidden_units)\n",
    "        x, gate_values = self.moe_dense2(x) # (B, hidden_units)\n",
    "        x = self.relu2(x)\n",
    "        x = self.softmax(self.dense3(x))    # (B, fan_out)\n",
    "        return x, gate_values               # (B, fan_out), (B, num_experts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(\n",
    "    y_pred:Tensor, # (B, fan_out)\n",
    "    y_true:Tensor, # (B,)\n",
    "    gate_values:Tensor, # (B, num_experts),\n",
    "    importance_weight:float,\n",
    "    load_balancing_weight:float\n",
    "):\n",
    "    Lce = nn.functional.cross_entropy(y_pred, y_true)\n",
    "\n",
    "    # Balancing expert utilization/importance\n",
    "    importance = gate_values.sum(dim=0) # (num_experts,)\n",
    "    Limportance = importance_weight * importance.std().div(importance.mean()).square()\n",
    "\n",
    "    # Load balancing Loss: encourage experts to receive equal number of samples. (switch transormer type)\n",
    "    num_experts = gate_values.size(1)\n",
    "    importance_mean = gate_values.mean(dim=0)  # avg prob mass per expert\n",
    "    load = (gate_values > 0).float().mean(dim=0)  # fraction of tokens sent to each expert\n",
    "    Lload = load_balancing_weight * (importance_mean * load).mean() * (num_experts ** 2)\n",
    "\n",
    "    return Lce, Limportance, Lload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(y_true:Tensor, y_probs:Tensor):\n",
    "    y_pred = torch.argmax(y_probs, dim=-1)\n",
    "    return (y_true==y_pred).float().sum()/len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    lr:float = 1e-3\n",
    "    weight_decay:float = 0.0\n",
    "    batch_size:int = 32\n",
    "    num_epochs:int = 50\n",
    "\n",
    "    HIDDEN_UNITS:int = 1024\n",
    "    \n",
    "    NUM_EXPERTS:int = 10\n",
    "    TOPK:int = 3\n",
    "    IMPORTANCE_WEIGHT:float = 0.1\n",
    "    LOAD_BALANCING_WEIGHT:float = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_model = DenseModel(\n",
    "    fan_in=FAN_IN,\n",
    "    hidden_units=config.HIDDEN_UNITS,\n",
    "    fan_out=NUM_CLASSES\n",
    "); print(\"Number of parameters in naive_model:\", sum(p.numel() for p in naive_model.parameters())/1e6, \"Million\")\n",
    "moe_model = MoEDenseModel(\n",
    "    fan_in=FAN_IN,\n",
    "    hidden_units=config.HIDDEN_UNITS,\n",
    "    fan_out=NUM_CLASSES,\n",
    "    num_experts=config.NUM_EXPERTS,\n",
    "    topk=config.TOPK\n",
    "); print(\"Number of parameters in moe_model:\", sum(p.numel() for p in moe_model.parameters())/1e6, \"Million\")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=config.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model:DenseModel|MoEDenseModel, loss_fn:tp.Callable):\n",
    "    try:\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "        \n",
    "        loss_history = {}\n",
    "        accuracy_history = {}\n",
    "        total_steps = 0\n",
    "        for epoch in range(1, config.num_epochs+1):\n",
    "            t0 = time.time()\n",
    "            for step, (X, y_true) in enumerate(train_loader):\n",
    "                total_steps += 1\n",
    "                y_pred = model(X) # (B, num_classes)\n",
    "                losses:tp.Sequence[Tensor] = loss_fn(y_pred, y_true, importance_weight=config.IMPORTANCE_WEIGHT, load_balancing_weight=config.LOAD_BALANCING_WEIGHT)\n",
    "                loss:Tensor = sum(losses, start=torch.tensor(0.0, device=X.device))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                loss_history[total_steps] = losses[0].cpu().detach().item()\n",
    "            \n",
    "            t1 = time.time()\n",
    "            acc = get_accuracy(y_val, model(X_VAL))\n",
    "            accuracy_history[total_steps] = acc\n",
    "            print(f\"|| Epoch: {epoch} || Loss: {loss_history[total_steps]:.4f} || Accuracy: {accuracy_history[total_steps]:.4f} || dt: {(t1-t0):.4f}s ||\")\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Training interrupted by user.\")\n",
    "    return loss_history, accuracy_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naivemodel_losses, naivemodel_accuracies = train_model(\n",
    "    naive_model, loss_fn=lambda pred, true, **kwargs: (nn.functional.cross_entropy(pred, true), 0, 0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(naivemodel_losses.keys()), list(naivemodel_losses.values()))\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Naive Model Loss')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "plt.plot(list(naivemodel_accuracies.keys()), list(naivemodel_accuracies.values()))\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Naive Model Accuracy')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moemodel_losses, moemodel_accuracies = train_model(\n",
    "    moe_model, loss_fn=loss_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list(moemodel_losses.keys()), list(moemodel_losses.values()))\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('MoE Model Loss')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "plt.plot(list(moemodel_accuracies.keys()), list(moemodel_accuracies.values()))\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('MoE Model Accuracy')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NeuroForge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
